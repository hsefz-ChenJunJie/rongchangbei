# AIå¯¹è¯åº”ç”¨åç«¯éƒ¨ç½²æŒ‡å—

## æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›AIå¯¹è¯åº”ç”¨åç«¯çš„å®Œæ•´éƒ¨ç½²æŒ‡å—ï¼ŒåŒ…æ‹¬å¼€å‘ç¯å¢ƒéƒ¨ç½²å’Œç”Ÿäº§ç¯å¢ƒDockeréƒ¨ç½²ä¸¤ç§æ–¹å¼ã€‚

**ğŸ™ï¸ æœ€æ–°ç‰¹æ€§ï¼š** é¡¹ç›®ç°å·²é›†æˆWhisperé«˜ç²¾åº¦è¯­éŸ³è¯†åˆ«æœåŠ¡ï¼Œæ”¯æŒGPU/CPUæ¨ç†ï¼Œæä¾›æ¯”Voskæ›´å¥½çš„è¯†åˆ«å‡†ç¡®ç‡å’Œå¤šè¯­è¨€æ”¯æŒã€‚æ¨èä½¿ç”¨Whisperä½œä¸ºä¸»è¦STTæœåŠ¡ã€‚

## å¿«é€Ÿå¯¼èˆª

- ğŸ“‹ **[è¯¦ç»†é…ç½®è¯´æ˜](CONFIGURATION.md)** - æ‰€æœ‰é…ç½®é¡¹çš„å®Œæ•´è¯´æ˜
- ğŸš€ **[éƒ¨ç½²æŒ‡å—](#éƒ¨ç½²æŒ‡å—)** - å¼€å‘å’Œç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
- ğŸ³ **[Dockeréƒ¨ç½²](#dockeréƒ¨ç½²)** - å®¹å™¨åŒ–ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ï¼ˆæ¨èï¼‰
- ğŸ”§ **[æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)** - å¸¸è§é—®é¢˜è§£å†³æ–¹æ¡ˆ
- ğŸ—ï¸ **[é¡¹ç›®ç»“æ„](#é¡¹ç›®ç»“æ„)** - ä»£ç ç»„ç»‡ç»“æ„

## ç³»ç»Ÿè¦æ±‚

### åŸºç¡€ç¯å¢ƒ
- **å¼€å‘ç¯å¢ƒ**: Python 3.12+ ï¼ˆæ¨è3.12ï¼Œ3.9+å¯ç”¨ï¼‰
- **ç”Ÿäº§ç¯å¢ƒ**: Docker 20.0+ + Docker Compose 2.0+
- Git
- ç½‘ç»œè¿æ¥ï¼ˆç”¨äºä¸‹è½½ä¾èµ–å’Œæ¨¡å‹ï¼‰

### å¯é€‰ç»„ä»¶
- Whisperè¯­éŸ³è¯†åˆ«æ¨¡å‹ï¼ˆæ¨èçš„STTæœåŠ¡ï¼‰
- Voskè¯­éŸ³è¯†åˆ«æ¨¡å‹ï¼ˆå¤‡ç”¨STTæœåŠ¡ï¼‰
- OpenRouter APIå¯†é’¥ï¼ˆçœŸå®LLMæœåŠ¡ï¼‰
- CUDAæ”¯æŒï¼ˆWhisper GPUæ¨ç†ï¼Œå¯é€‰ï¼‰
- Nginxï¼ˆåå‘ä»£ç†ï¼Œç”Ÿäº§ç¯å¢ƒæ¨èï¼‰

### ğŸ“‹ é‡è¦é…ç½®è¯´æ˜

æœ¬åº”ç”¨æ”¯æŒä¸°å¯Œçš„é…ç½®é€‰é¡¹ï¼Œè¯¦ç»†é…ç½®è¯´æ˜è¯·å‚è€ƒï¼š**[CONFIGURATION.md](CONFIGURATION.md)**

**å¿«é€Ÿé…ç½®è¦ç‚¹ï¼š**
- ğŸ”‘ **OpenRouter API**: é…ç½® `OPENROUTER_API_KEY` å¯ç”¨çœŸå®LLMæœåŠ¡
- ğŸ™ï¸ **è¯­éŸ³è¯†åˆ«**: ä¸‹è½½Whisperæ¨¡å‹å¯ç”¨é«˜è´¨é‡STTæœåŠ¡ï¼ˆæ¨èï¼‰
- ğŸ¯ **STTå¼•æ“é€‰æ‹©**: é€šè¿‡ `STT_ENGINE` é€‰æ‹©whisper/vosk/mock
- ğŸš€ **GPUåŠ é€Ÿ**: é…ç½® `WHISPER_DEVICE=cuda` å¯ç”¨GPUæ¨ç†ï¼ˆå¯é€‰ï¼‰
- ğŸŒ **ç½‘ç»œè®¾ç½®**: ç”Ÿäº§ç¯å¢ƒéœ€è®¾ç½® `HOST=0.0.0.0`
- ğŸ“ **æ—¥å¿—é…ç½®**: å¯è°ƒæ•´ `LOG_LEVEL` å’Œ `LOG_FORMAT`

## é¡¹ç›®ç»“æ„

```
backend/
â”œâ”€â”€ app/                    # åº”ç”¨æ ¸å¿ƒä»£ç 
â”‚   â”œâ”€â”€ api/               # APIè·¯ç”±
â”‚   â”œâ”€â”€ models/            # æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ services/          # æ ¸å¿ƒæœåŠ¡
â”‚   â”œâ”€â”€ websocket/         # WebSocketå¤„ç†
â”‚   â””â”€â”€ main.py           # åº”ç”¨å…¥å£
â”œâ”€â”€ config/                # é…ç½®ç®¡ç†
â”œâ”€â”€ model/                 # AIæ¨¡å‹å­˜å‚¨
â”‚   â”œâ”€â”€ whisper-models/    # Whisperè¯­éŸ³è¯†åˆ«æ¨¡å‹
â”‚   â””â”€â”€ vosk-model/        # Voskè¯­éŸ³è¯†åˆ«æ¨¡å‹ï¼ˆå¤‡ç”¨ï¼‰
â”œâ”€â”€ requirements.txt       # Pythonä¾èµ–
â”œâ”€â”€ Dockerfile            # Dockeré•œåƒæ„å»ºé…ç½®
â”œâ”€â”€ docker-compose.yml    # Docker ComposeæœåŠ¡ç¼–æ’
â”œâ”€â”€ deploy-docker.sh      # Dockeréƒ¨ç½²è„šæœ¬
â”œâ”€â”€ .env.example         # ç¯å¢ƒå˜é‡ç¤ºä¾‹
â””â”€â”€ README.md            # æœ¬æ–‡æ¡£
```

---

## æ–¹å¼ä¸€ï¼šå¼€å‘ç¯å¢ƒéƒ¨ç½²

### 1. ç¯å¢ƒå‡†å¤‡

#### 1.1 å…‹éš†é¡¹ç›®
```bash
git clone <your-repository-url>
cd è£æ˜¶æ¯é¡¹ç›®/backend
```

#### 1.2 åˆ›å»ºPythonè™šæ‹Ÿç¯å¢ƒ

> âš ï¸ **é‡è¦æé†’**ï¼šæœ¬é¡¹ç›®éœ€è¦Python 3.9+ï¼Œæ¨èä½¿ç”¨Python 3.12ã€‚

```bash
# ç¡®è®¤Pythonç‰ˆæœ¬ï¼ˆå¿…é¡»3.9+ï¼‰
python --version

# ä½¿ç”¨venv
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ–
venv\Scripts\activate     # Windows

# ä½¿ç”¨conda/mambaï¼ˆæ¨èï¼‰
mamba create -n rongchang python=3.12
mamba activate rongchang
```

#### 1.3 å®‰è£…Pythonä¾èµ–
```bash
pip install -r requirements.txt
```

### 2. é…ç½®è®¾ç½®

#### 2.1 ç¯å¢ƒå˜é‡é…ç½®
åˆ›å»º `.env` æ–‡ä»¶ï¼ˆåŸºç¡€é…ç½®ç¤ºä¾‹ï¼‰ï¼š
```bash
# OpenRouter LLMé…ç½®ï¼ˆå¯é€‰ï¼‰
OPENROUTER_API_KEY=your_api_key_here
OPENROUTER_MODEL=anthropic/claude-3-haiku
OPENROUTER_TEMPERATURE=0.7

# STTè¯­éŸ³è¯†åˆ«é…ç½®
STT_ENGINE=whisper    # é€‰æ‹©å¼•æ“: whisperï¼ˆæ¨èï¼‰/vosk/mock

# Whisper STTé…ç½®ï¼ˆæ¨èï¼‰
USE_WHISPER=true
WHISPER_MODEL_NAME=base
WHISPER_MODEL_PATH=model/whisper-models
WHISPER_DEVICE=auto
WHISPER_COMPUTE_TYPE=int8

# Vosk STTé…ç½®ï¼ˆå¤‡ç”¨ï¼‰
USE_REAL_VOSK=false
VOSK_MODEL_PATH=model/vosk-model
VOSK_SAMPLE_RATE=16000

# æœåŠ¡å™¨é…ç½®
HOST=127.0.0.1
PORT=8000
DEBUG=true
LOG_LEVEL=INFO
```

> ğŸ’¡ **å®Œæ•´é…ç½®è¯´æ˜**: æŸ¥çœ‹ [CONFIGURATION.md](CONFIGURATION.md) äº†è§£æ‰€æœ‰é…ç½®é¡¹çš„è¯¦ç»†è¯´æ˜ã€é»˜è®¤å€¼å’Œæœ€ä½³å®è·µã€‚

#### 2.2 ä¸‹è½½Whisperæ¨¡å‹ï¼ˆæ¨èï¼‰

**æ–¹å¼ä¸€ï¼šä½¿ç”¨è‡ªåŠ¨åŒ–è„šæœ¬ï¼ˆæ¨èï¼‰**

é¡¹ç›®æä¾›äº†è‡ªåŠ¨ä¸‹è½½å’Œè½¬æ¢è„šæœ¬ï¼Œå¯ä»¥è½»æ¾è·å–Whisperæ¨¡å‹ï¼š

```bash
# ä¸‹è½½æ¨èçš„baseæ¨¡å‹ï¼ˆçº¦74MBï¼Œæ€§èƒ½å’Œå‡†ç¡®ç‡å¹³è¡¡ï¼‰
python scripts/download_whisper_models.py --model base --verify

# ä¸‹è½½æ‰€æœ‰æ¨èæ¨¡å‹ï¼ˆbaseã€smallã€mediumï¼‰
python scripts/download_whisper_models.py --all --verify

# ä¸‹è½½ç‰¹å®šæ¨¡å‹å¹¶æŒ‡å®šé‡åŒ–ç±»å‹
python scripts/download_whisper_models.py --model small --quantization int8 --verify
```

**æ–¹å¼äºŒï¼šæ‰‹åŠ¨ä¸‹è½½å’Œè½¬æ¢**

å¦‚æœéœ€è¦æ‰‹åŠ¨æ“ä½œæˆ–å®šåˆ¶åŒ–å®‰è£…ï¼š

```bash
# å®‰è£…è½¬æ¢å·¥å…·
pip install ctranslate2 transformers[torch]

# åˆ›å»ºæ¨¡å‹ç›®å½•
mkdir -p model/whisper-models

# è½¬æ¢baseæ¨¡å‹ï¼ˆæ¨èï¼‰
ct2-transformers-converter \
    --model openai/whisper-base \
    --output_dir model/whisper-models/base-ct2 \
    --copy_files tokenizer.json preprocessor_config.json \
    --quantization int8

# éªŒè¯æ¨¡å‹å®‰è£…
python -c "
from faster_whisper import WhisperModel
model = WhisperModel('model/whisper-models/base-ct2', device='cpu')
print('âœ… Whisperæ¨¡å‹åŠ è½½æˆåŠŸ!')
"
```

**æ¨¡å‹é€‰æ‹©å»ºè®®ï¼š**

| æ¨¡å‹åç§° | å¤§å° | å†…å­˜éœ€æ±‚ | å‡†ç¡®æ€§ | æ¨èç”¨é€” |
|----------|------|----------|--------|----------|
| `base` | ~74MB | ~1GB | è‰¯å¥½ | **é€šç”¨æ¨è** |
| `small` | ~244MB | ~2GB | å¾ˆå¥½ | é«˜è´¨é‡éœ€æ±‚ |
| `medium` | ~769MB | ~5GB | ä¼˜ç§€ | ä¸“ä¸šåº”ç”¨ |
| `large-v3` | ~1550MB | ~10GB | æä½³ | æœ€é«˜ç²¾åº¦ |

> ğŸ’¡ **æç¤º**ï¼š
> - é¦–æ¬¡ä½¿ç”¨å»ºè®®é€‰æ‹© `base` æ¨¡å‹ï¼Œå¹³è¡¡äº†æ€§èƒ½å’Œå‡†ç¡®ç‡
> - å¦‚æœ‰GPUæ”¯æŒï¼Œå¯è®¾ç½® `WHISPER_DEVICE=cuda` æå‡æ¨ç†é€Ÿåº¦
> - è¯¦ç»†çš„æ¨¡å‹ç®¡ç†æŒ‡å—è¯·æŸ¥çœ‹ `backend/model/WHISPER_MODELS.md`

#### 2.3 ä¸‹è½½Voskæ¨¡å‹ï¼ˆå¯é€‰å¤‡ç”¨ï¼‰

å¦‚æœéœ€è¦Voskä½œä¸ºå¤‡ç”¨STTæœåŠ¡ï¼š

```bash
# è¿›å…¥Voskæ¨¡å‹ç›®å½•
cd backend/model/vosk-model

# ä¸‹è½½ä¸­æ–‡æ¨¡å‹ï¼ˆçº¦500MBï¼‰
wget https://alphacephei.com/vosk/models/vosk-model-cn-0.22.zip
unzip vosk-model-cn-0.22.zip
mv vosk-model-cn-0.22/* .
rm -rf vosk-model-cn-0.22 vosk-model-cn-0.22.zip

# éªŒè¯æ¨¡å‹æ–‡ä»¶
ls -la  # åº”è¯¥çœ‹åˆ° am/, conf/, graph/, ivector/ ç›®å½•
```

> âš ï¸ **é‡è¦**ï¼š
> - å¦‚æœä¸ä¸‹è½½ä»»ä½•æ¨¡å‹ï¼Œåº”ç”¨å°†ä½¿ç”¨Mock STTæœåŠ¡ï¼ˆé€‚åˆå¼€å‘æµ‹è¯•ï¼‰
> - æ¨èä½¿ç”¨Whisperè€ŒéVoskï¼ŒWhisperå…·æœ‰æ›´é«˜çš„è¯†åˆ«å‡†ç¡®ç‡å’Œæ›´å¥½çš„å¤šè¯­è¨€æ”¯æŒ

### 3. å¯åŠ¨æœåŠ¡

#### 3.1 å¼€å‘æ¨¡å¼å¯åŠ¨
```bash
# ç¡®ä¿åœ¨backendç›®å½•ä¸‹
cd /path/to/è£æ˜¶æ¯é¡¹ç›®/backend

# æ¨èæ–¹å¼ï¼šä½¿ç”¨uvicornç›´æ¥å¯åŠ¨
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

# æˆ–ä½¿ç”¨Pythonæ¨¡å—å¯åŠ¨ï¼ˆéœ€è¦è®¾ç½®PYTHONPATHï¼‰
PYTHONPATH=. python -m app.main

# æœ€ç®€å•æ–¹å¼ï¼šç›´æ¥è¿è¡Œmain.py
python app/main.py
```

#### 3.2 éªŒè¯éƒ¨ç½²
```bash
# æ£€æŸ¥åç«¯æ€»ä½“å¥åº·çŠ¶æ€
curl http://localhost:8000/

# æ£€æŸ¥å¯¹è¯æœåŠ¡å¥åº·çŠ¶æ€
curl http://localhost:8000/conversation/health

# é¢„æœŸå“åº”ï¼ˆæ ¹å¥åº·æ£€æŸ¥ï¼‰
{
  "status": "healthy",
  "timestamp": "2024-01-XX...",
  "service": "AIå¯¹è¯åº”ç”¨åç«¯æ€»æœåŠ¡",
  "version": "1.0.0",
  "description": "åç«¯è¿›ç¨‹è¿è¡Œæ­£å¸¸ï¼Œå„æœåŠ¡çŠ¶æ€è‰¯å¥½"
}

# æµ‹è¯•WebSocketè¿æ¥
# ä½¿ç”¨æµè§ˆå™¨å¼€å‘è€…å·¥å…·æˆ–WebSocketå®¢æˆ·ç«¯è¿æ¥ï¼š
# ws://localhost:8000/conversation
```

#### 3.3 è¿è¡ŒåŠŸèƒ½æµ‹è¯•ï¼ˆæ¨èï¼‰
```bash
# è¿è¡Œå®Œæ•´çš„åŠŸèƒ½éªŒè¯æµ‹è¯•å¥—ä»¶
cd ../tests/backend
python run_all_tests.py

# æˆ–å•ç‹¬è¿è¡Œç‰¹å®šæµ‹è¯•
python test_audio_stream_fix.py      # éŸ³é¢‘æµå¤„ç†æµ‹è¯•
python test_response_count_fix.py    # response_countæ›´æ–°æµ‹è¯•
```

> ğŸ“‹ **æµ‹è¯•è¯¦æƒ…**: å®Œæ•´çš„æµ‹è¯•è¯´æ˜è¯·å‚è€ƒ [`../tests/backend/README.md`](../tests/backend/README.md)

### 4. å¼€å‘ç¯å¢ƒé…ç½®è°ƒä¼˜

#### 4.1 æ—¥å¿—é…ç½®
```bash
# å¼€å¯è¯¦ç»†æ—¥å¿—
export LOG_LEVEL=DEBUG

# æˆ–åœ¨ä»£ç ä¸­ä¿®æ”¹ config/settings.py
log_level: str = "DEBUG"
```

#### 4.2 çƒ­é‡è½½å¼€å‘
```bash
# ä½¿ç”¨uvicornçš„è‡ªåŠ¨é‡è½½åŠŸèƒ½
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

#### 4.3 è°ƒè¯•é…ç½®
åœ¨IDEä¸­é…ç½®è°ƒè¯•ï¼š
- **å¯åŠ¨è„šæœ¬**: `app/main.py`  
- **å·¥ä½œç›®å½•**: `backend/`
- **ç¯å¢ƒå˜é‡**: æŒ‰éœ€è®¾ç½®ä¸Šè¿°ç¯å¢ƒå˜é‡

---

## æ–¹å¼äºŒï¼šDockeréƒ¨ç½²ï¼ˆæ¨èç”Ÿäº§ç¯å¢ƒï¼‰

### 1. å¿«é€Ÿéƒ¨ç½²

ä½¿ç”¨æä¾›çš„éƒ¨ç½²è„šæœ¬ï¼Œä¸€é”®éƒ¨ç½²å®¹å™¨åŒ–æœåŠ¡ï¼š

```bash
# ç»™è„šæœ¬æ‰§è¡Œæƒé™
chmod +x deploy-docker.sh

# ä¸€é”®éƒ¨ç½²ï¼ˆè‡ªåŠ¨å¯ç”¨åŠ é€Ÿä¼˜åŒ–ï¼‰
./deploy-docker.sh

# æˆ–è€…æ‰‹åŠ¨ä½¿ç”¨ Docker Compose
export DOCKER_BUILDKIT=1  # å¯ç”¨BuildKit
docker compose up -d --build
```

**ğŸš€ æ€§èƒ½ä¼˜åŒ–ç‰¹æ€§ï¼š**
- âœ… **apté•œåƒåŠ é€Ÿ**: ä½¿ç”¨é˜¿é‡Œäº‘é•œåƒæº
- âœ… **pipé•œåƒåŠ é€Ÿ**: ä½¿ç”¨æ¸…åå¤§å­¦é•œåƒæº  
- âœ… **uvåŒ…ç®¡ç†å™¨**: æ¯”pipå¿«10-100å€çš„PythonåŒ…å®‰è£…
- âœ… **BuildKitç¼“å­˜**: æ™ºèƒ½å±‚ç¼“å­˜ï¼Œå¤§å¹…å‡å°‘é‡å¤æ„å»ºæ—¶é—´
- âœ… **å¤šé˜¶æ®µæ„å»º**: æœ€å°åŒ–æœ€ç»ˆé•œåƒä½“ç§¯
- âœ… **ç¼“å­˜æŒ‚è½½**: ä¾èµ–å®‰è£…ç¼“å­˜æŒä¹…åŒ–

### 2. ç¯å¢ƒé…ç½®

#### 2.1 é…ç½®ä¼˜å…ˆçº§è¯´æ˜

ğŸ¯ **é‡è¦ç‰¹æ€§ï¼šæ”¯æŒçµæ´»çš„ç¯å¢ƒé…ç½®æ–¹å¼**

**é…ç½®ä¼˜å…ˆçº§ï¼ˆä»é«˜åˆ°ä½ï¼‰ï¼š**
1. **`.env` æ–‡ä»¶**ï¼šå¦‚æœbackendç›®å½•ä¸‹å­˜åœ¨.envæ–‡ä»¶ï¼Œä¼˜å…ˆä½¿ç”¨å…¶ä¸­çš„é…ç½®
2. **docker-compose.ymlé»˜è®¤å€¼**ï¼šä½œä¸ºåå¤‡é…ç½®ï¼Œç¡®ä¿æœåŠ¡æ­£å¸¸å¯åŠ¨

**ä½¿ç”¨åœºæ™¯ï¼š**
- **å¼€å‘ç¯å¢ƒ**ï¼šæ— .envæ–‡ä»¶ï¼Œä½¿ç”¨docker-compose.ymlä¸­çš„é»˜è®¤å€¼
- **ç”Ÿäº§ç¯å¢ƒ**ï¼šåˆ›å»º.envæ–‡ä»¶ï¼Œè¦†ç›–éœ€è¦è‡ªå®šä¹‰çš„é…ç½®é¡¹

#### 2.2 ç¯å¢ƒå˜é‡è®¾ç½®

**ç”Ÿäº§ç¯å¢ƒé…ç½®ï¼ˆæ¨èï¼‰ï¼š**
```bash
# å¤åˆ¶Dockerç¯å¢ƒå˜é‡ç¤ºä¾‹æ–‡ä»¶
cp .env.docker.example .env

# ç¼–è¾‘ç¯å¢ƒå˜é‡é…ç½®
nano .env
```

**.envæ–‡ä»¶é…ç½®ç¤ºä¾‹ï¼š**
```bash
# LLMæœåŠ¡é…ç½®
OPENROUTER_API_KEY=sk-or-v1-your-actual-api-key-here
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
OPENROUTER_MODEL=qwen/qwen3-235b-a22b:free

# STTæœåŠ¡é…ç½®
STT_ENGINE=whisper
USE_WHISPER=true
WHISPER_MODEL_NAME=base
WHISPER_MODEL_PATH=/app/model/whisper-models
WHISPER_DEVICE=auto
WHISPER_COMPUTE_TYPE=int8

# å®‰å…¨é…ç½®
ALLOWED_ORIGINS=["https://yourdomain.com"]

# åŸºç¡€é…ç½®
DEBUG=false
LOG_LEVEL=INFO
```

**å¼€å‘ç¯å¢ƒï¼ˆæ— éœ€åˆ›å»º.envæ–‡ä»¶ï¼‰ï¼š**
å¦‚æœä¸åˆ›å»º.envæ–‡ä»¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ä½¿ç”¨docker-compose.ymlä¸­çš„é»˜è®¤é…ç½®ï¼Œé€‚åˆå¼€å‘å’Œæµ‹è¯•ç¯å¢ƒã€‚

#### 2.3 æ¨¡å‹æ–‡ä»¶é…ç½®

**Whisperæ¨¡å‹é…ç½®ï¼ˆæ¨èï¼‰ï¼š**
```bash
# ä½¿ç”¨é¡¹ç›®è„šæœ¬è‡ªåŠ¨ä¸‹è½½å’Œè½¬æ¢Whisperæ¨¡å‹
python scripts/download_whisper_models.py --model base --verify

# æˆ–ä¸‹è½½å¤šä¸ªæ¨èæ¨¡å‹
python scripts/download_whisper_models.py --all --verify

# éªŒè¯Whisperæ¨¡å‹
ls -la model/whisper-models/  # åº”è¯¥çœ‹åˆ° base-ct2/ ç­‰ç›®å½•
```

**Voskæ¨¡å‹é…ç½®ï¼ˆå¯é€‰å¤‡ç”¨ï¼‰ï¼š**
```bash
# åˆ›å»ºVoskæ¨¡å‹ç›®å½•
mkdir -p model/vosk-model

# ä¸‹è½½ä¸­æ–‡æ¨¡å‹
cd model/vosk-model
wget https://alphacephei.com/vosk/models/vosk-model-cn-0.22.zip
unzip vosk-model-cn-0.22.zip
mv vosk-model-cn-0.22/* .
rm -rf vosk-model-cn-0.22*

# éªŒè¯æ¨¡å‹ç»“æ„
ls -la  # åº”è¯¥çœ‹åˆ° am/, conf/, graph/, ivector/ ç›®å½•
```

**GPUæ”¯æŒé…ç½®ï¼ˆå¯é€‰ï¼‰ï¼š**
```bash
# å¦‚æœæœ‰NVIDIA GPUä¸”å¸Œæœ›ä½¿ç”¨GPUåŠ é€ŸWhisperæ¨ç†
# ç¡®ä¿å·²å®‰è£…CUDAå’Œç›¸åº”çš„PyTorchç‰ˆæœ¬
# åœ¨.envæ–‡ä»¶ä¸­é…ç½®ï¼š
WHISPER_DEVICE=cuda
WHISPER_COMPUTE_TYPE=float16

# éªŒè¯GPUå¯ç”¨æ€§
docker compose exec ai-dialogue-backend python -c "
import torch
print(f'CUDA available: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'GPU devices: {torch.cuda.device_count()}')
    print(f'Current device: {torch.cuda.get_device_name(0)}')
"
```

### 3. å®¹å™¨ç®¡ç†

#### 3.1 åŸºæœ¬æ“ä½œ
```bash
# å¯åŠ¨æœåŠ¡
./deploy-docker.sh
# æˆ–
docker compose up -d

# åœæ­¢æœåŠ¡
./deploy-docker.sh --stop
# æˆ–
docker compose down

# é‡å¯æœåŠ¡
./deploy-docker.sh --restart
# æˆ–
docker compose restart

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
./deploy-docker.sh --status
# æˆ–
docker compose ps
```

#### 3.2 æ—¥å¿—æŸ¥çœ‹
```bash
# æŸ¥çœ‹å®æ—¶æ—¥å¿—
./deploy-docker.sh --logs
# æˆ–
docker compose logs -f

# æŸ¥çœ‹å®¹å™¨çŠ¶æ€
docker compose ps

# æŸ¥çœ‹æœ€è¿‘æ—¥å¿—
docker compose logs --tail=50
```

#### 3.3 å¼ºåˆ¶é‡æ–°æ„å»º
```bash
# å¼ºåˆ¶é‡å»ºé•œåƒï¼ˆä½¿ç”¨ä¼˜åŒ–æ„å»ºï¼‰
./deploy-docker.sh --build --no-cache

# ä½¿ç”¨å¤šé˜¶æ®µæ„å»ºï¼ˆè¿›ä¸€æ­¥ä¼˜åŒ–é•œåƒå¤§å°ï¼‰
docker build -f Dockerfile.multi-stage -t ai-dialogue-backend .

# æˆ–æ‰‹åŠ¨æ“ä½œ
docker compose down
docker compose build --no-cache
docker compose up -d
```

**âš¡ æ„å»ºæ€§èƒ½å¯¹æ¯”ï¼š**
| æ–¹å¼ | é¦–æ¬¡æ„å»ºæ—¶é—´ | é‡æ–°æ„å»ºæ—¶é—´ | é•œåƒå¤§å° |
|------|-------------|-------------|----------|
| ä¼ ç»Ÿpip | ~8-12åˆ†é’Ÿ | ~5-8åˆ†é’Ÿ | ~800MB |
| uv + é•œåƒåŠ é€Ÿ | ~2-4åˆ†é’Ÿ | ~30ç§’-2åˆ†é’Ÿ | ~600MB |
| å¤šé˜¶æ®µæ„å»º | ~3-5åˆ†é’Ÿ | ~1-3åˆ†é’Ÿ | ~400MB |

### 4. æœåŠ¡ç›‘æ§

#### 4.1 å¥åº·æ£€æŸ¥
```bash
# æ‰‹åŠ¨å¥åº·æ£€æŸ¥
curl http://localhost:8000/
curl http://localhost:8000/conversation/health

# æŸ¥çœ‹å®¹å™¨å¥åº·çŠ¶æ€
docker compose ps
```

#### 4.2 æ€§èƒ½ç›‘æ§
```bash
# æŸ¥çœ‹å®¹å™¨èµ„æºä½¿ç”¨
docker stats

# æŸ¥çœ‹å®¹å™¨è¯¦ç»†ä¿¡æ¯
docker compose exec ai-dialogue-backend ps aux

# æŸ¥çœ‹ç«¯å£æ˜ å°„
docker compose port ai-dialogue-backend 8000
```

### 5. ç”Ÿäº§ç¯å¢ƒé…ç½®

#### 5.1 Nginxåå‘ä»£ç†
```nginx
# /etc/nginx/sites-available/ai-dialogue-backend
server {
    listen 80;
    server_name your-domain.com;

    location / {
        proxy_pass http://127.0.0.1:8000;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # WebSocketæ”¯æŒ
        proxy_read_timeout 86400;
        proxy_send_timeout 86400;
    }
}
```

#### 5.2 SSL/TLSé…ç½®
```bash
# ä½¿ç”¨ Let's Encrypt
sudo apt install certbot python3-certbot-nginx
sudo certbot --nginx -d your-domain.com
```

### 6. æ•°æ®æŒä¹…åŒ–

#### 6.1 æ—¥å¿—æŒä¹…åŒ–
```yaml
# docker-compose.yml ä¸­å·²é…ç½®
volumes:
  - ./logs:/app/logs        # æ—¥å¿—ç›®å½•æ˜ å°„åˆ°ä¸»æœº
  - ./model:/app/model:ro   # æ¨¡å‹ç›®å½•åªè¯»æ˜ å°„
```

#### 6.2 å¤‡ä»½å’Œæ¢å¤
```bash
# å¤‡ä»½é…ç½®å’Œæ—¥å¿—
tar -czf backup-$(date +%Y%m%d).tar.gz \
    .env docker-compose.yml Dockerfile \
    logs/ model/

# æ¢å¤
tar -xzf backup-20240101.tar.gz
docker compose up -d
```

### 7. å¤šç¯å¢ƒéƒ¨ç½²

#### 7.1 å¼€å‘ç¯å¢ƒ
```bash
# ä½¿ç”¨å¼€å‘é…ç½®
cp .env.example .env.dev
# ç¼–è¾‘ .env.dev è®¾ç½® DEBUG=true
docker compose -f docker-compose.yml --env-file .env.dev up -d
```

#### 7.2 ç”Ÿäº§ç¯å¢ƒ
```bash
# ä½¿ç”¨ç”Ÿäº§é…ç½®
cp .env.example .env.prod
# ç¼–è¾‘ .env.prod è®¾ç½®ç”Ÿäº§å‚æ•°
docker compose -f docker-compose.yml --env-file .env.prod up -d
```

### 8. æ•…éšœæ’é™¤

#### 8.1 å®¹å™¨æ— æ³•å¯åŠ¨
```bash
# æŸ¥çœ‹æ„å»ºæ—¥å¿—
docker compose build --no-cache

# æŸ¥çœ‹å¯åŠ¨æ—¥å¿—
docker compose logs ai-dialogue-backend

# è¿›å…¥å®¹å™¨è°ƒè¯•
docker compose exec ai-dialogue-backend bash
```

#### 8.2 ç½‘ç»œè¿æ¥é—®é¢˜
```bash
# æ£€æŸ¥ç«¯å£æ˜ å°„
docker compose ps
docker port ai-dialogue-backend

# æ£€æŸ¥å®¹å™¨ç½‘ç»œ
docker network ls
docker network inspect backend_ai-dialogue-network
```

### 9. å‡çº§å’Œç»´æŠ¤

#### 9.1 åº”ç”¨å‡çº§
```bash
# æ‹‰å–æœ€æ–°ä»£ç 
git pull origin main

# é‡æ–°æ„å»ºå¹¶éƒ¨ç½²
./deploy-docker.sh --build

# æˆ–æ‰‹åŠ¨æ“ä½œ
docker compose down
docker compose build
docker compose up -d
```

#### 9.2 æ¸…ç†èµ„æº
```bash
# æ¸…ç†æœªä½¿ç”¨çš„é•œåƒå’Œå®¹å™¨
./deploy-docker.sh --clean

# æˆ–æ‰‹åŠ¨æ¸…ç†
docker system prune -f
docker volume prune -f
```


---

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. ç«¯å£å†²çª
```bash
# æ£€æŸ¥ç«¯å£å ç”¨
sudo lsof -i :8000
sudo netstat -tulpn | grep 8000

# è§£å†³æ–¹æ¡ˆï¼šæ›´æ”¹ç«¯å£æˆ–åœæ­¢å†²çªæœåŠ¡
export PORT=8001
```

#### 2. Pythonç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜
```bash
# æ£€æŸ¥å½“å‰Pythonç‰ˆæœ¬
python --version

# å¦‚æœç‰ˆæœ¬ä½äº3.9ï¼Œè¯·å‡çº§Python
# Ubuntu/Debian
sudo apt update && sudo apt install python3.12 python3.12-venv python3.12-dev

# macOS (ä½¿ç”¨Homebrew)
brew install python@3.12

# åˆ›å»ºæ–°çš„è™šæ‹Ÿç¯å¢ƒ
python3.12 -m venv venv
source venv/bin/activate
```

#### 3. ä¾èµ–å®‰è£…å¤±è´¥
```bash
# æ›´æ–°pip
pip install --upgrade pip

# ä½¿ç”¨å›½å†…é•œåƒæº
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple/
```

#### 4. STTæœåŠ¡é—®é¢˜

**Whisperæ¨¡å‹åŠ è½½å¤±è´¥ï¼š**
```bash
# æ£€æŸ¥Whisperæ¨¡å‹æ–‡ä»¶
ls -la model/whisper-models/

# ç¡®ä¿æ¨¡å‹ç›®å½•ç»“æ„æ­£ç¡®
model/whisper-models/
â”œâ”€â”€ base-ct2/
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ model.bin
â”‚   â””â”€â”€ tokenizer.json
â””â”€â”€ small-ct2/  # å¦‚æœä¸‹è½½äº†å…¶ä»–æ¨¡å‹

# å¦‚æœæ¨¡å‹ä¸å­˜åœ¨ï¼Œé‡æ–°ä¸‹è½½
python scripts/download_whisper_models.py --model base --verify

# æƒé™é—®é¢˜
chmod -R 755 model/

# æµ‹è¯•æ¨¡å‹åŠ è½½
python -c "
from faster_whisper import WhisperModel
try:
    model = WhisperModel('model/whisper-models/base-ct2', device='cpu')
    print('âœ… Whisperæ¨¡å‹åŠ è½½æˆåŠŸ')
except Exception as e:
    print(f'âŒ Whisperæ¨¡å‹åŠ è½½å¤±è´¥: {e}')
"
```

**GPUæ¨ç†é—®é¢˜ï¼š**
```bash
# æ£€æŸ¥CUDAå¯ç”¨æ€§
python -c "
import torch
print(f'CUDA available: {torch.cuda.is_available()}')
print(f'PyTorch version: {torch.__version__}')
"

# å¦‚æœCUDAä¸å¯ç”¨ï¼Œåˆ‡æ¢åˆ°CPUæ¨ç†
export WHISPER_DEVICE=cpu
export WHISPER_COMPUTE_TYPE=int8
```

**STTå¼•æ“é€‰æ‹©é—®é¢˜ï¼š**
```bash
# æ£€æŸ¥å½“å‰STTå¼•æ“é…ç½®
echo "Current STT_ENGINE: $STT_ENGINE"

# åˆ‡æ¢åˆ°Mockæ¨¡å¼è¿›è¡Œæµ‹è¯•
export STT_ENGINE=mock

# æ£€æŸ¥ç¯å¢ƒå˜é‡
env | grep -E "(STT_|WHISPER_|VOSK_)"
```

**Voskæ¨¡å‹åŠ è½½å¤±è´¥ï¼ˆå¤‡ç”¨é€‰é¡¹ï¼‰ï¼š**
```bash
# æ£€æŸ¥Voskæ¨¡å‹æ–‡ä»¶
ls -la model/vosk-model/

# ç¡®ä¿æ¨¡å‹ç›®å½•ç»“æ„æ­£ç¡®
model/vosk-model/
â”œâ”€â”€ am/
â”œâ”€â”€ graph/
â”œâ”€â”€ ivector/
â””â”€â”€ conf/

# æƒé™é—®é¢˜
chmod -R 755 model/
```

#### 5. æ¨¡å—å¯¼å…¥é”™è¯¯ (Could not import module "main")
```bash
# é”™è¯¯ç°è±¡ï¼šError loading ASGI app. Could not import module "main"

# è§£å†³æ–¹æ¡ˆ1ï¼šä½¿ç”¨æ­£ç¡®çš„å¯åŠ¨å‘½ä»¤ï¼ˆæ¨èï¼‰
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

# è§£å†³æ–¹æ¡ˆ2ï¼šè®¾ç½®PYTHONPATHç¯å¢ƒå˜é‡
export PYTHONPATH=.
python -m app.main

# è§£å†³æ–¹æ¡ˆ3ï¼šç›´æ¥è¿è¡Œmain.py
python app/main.py

# ç¡®è®¤å·¥ä½œç›®å½•æ­£ç¡®ï¼ˆåº”åœ¨backendç›®å½•ä¸‹ï¼‰
pwd  # åº”æ˜¾ç¤º */è£æ˜¶æ¯é¡¹ç›®/backend
ls -la app/  # åº”èƒ½çœ‹åˆ°main.pyæ–‡ä»¶
```

#### 6. DockeræœåŠ¡é—®é¢˜

**å®¹å™¨å¯åŠ¨å¤±è´¥ï¼š**
```bash
# æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯
docker compose logs ai-dialogue-backend

# æ£€æŸ¥å®¹å™¨çŠ¶æ€
docker compose ps

# æŸ¥çœ‹é•œåƒæ„å»ºæ—¥å¿—
docker compose build --no-cache

# è¿›å…¥å®¹å™¨è°ƒè¯•
docker compose exec ai-dialogue-backend bash
```

**æƒé™é—®é¢˜ï¼š**
```bash
# æ£€æŸ¥æ–‡ä»¶æƒé™
ls -la logs/
ls -la model/

# ä¿®å¤æƒé™
chmod -R 755 logs/
chmod -R 755 model/
```

**ç¯å¢ƒå˜é‡é—®é¢˜ï¼š**
```bash
# æ£€æŸ¥ç¯å¢ƒå˜é‡æ–‡ä»¶
cat .env

# æŸ¥çœ‹å®¹å™¨ä¸­çš„ç¯å¢ƒå˜é‡
docker compose exec ai-dialogue-backend env | grep -E "(OPENROUTER|STT_|WHISPER_|VOSK_|LOG)"

# æµ‹è¯•æ‰‹åŠ¨å¯åŠ¨
docker compose exec ai-dialogue-backend python -m uvicorn app.main:app --host 0.0.0.0 --port 8000
```

#### 7. ç½‘ç»œè¿æ¥é—®é¢˜
```bash
# æ£€æŸ¥é˜²ç«å¢™è®¾ç½®
sudo ufw allow 8000
sudo firewall-cmd --permanent --add-port=8000/tcp

# æ£€æŸ¥å®¹å™¨ç«¯å£æ˜ å°„
docker compose ps
docker compose port ai-dialogue-backend 8000

# ç¡®è®¤æœåŠ¡ç›‘å¬æ­£ç¡®çš„åœ°å€
sudo netstat -tlnp | grep :8000
# åº”è¯¥æ˜¾ç¤º 0.0.0.0:8000 è€Œä¸æ˜¯ 127.0.0.1:8000
```

### æ—¥å¿—è°ƒè¯•

#### æŸ¥çœ‹å®æ—¶æ—¥å¿—
```bash
# Dockerå®¹å™¨æ—¥å¿—
docker compose logs -f ai-dialogue-backend

# åº”ç”¨æ—¥å¿—æ–‡ä»¶
tail -f logs/app.log

# ç­›é€‰ç‰¹å®šçº§åˆ«æ—¥å¿—
docker compose logs ai-dialogue-backend | grep ERROR
```

#### æ€§èƒ½ç›‘æ§
```bash
# å®¹å™¨èµ„æºä½¿ç”¨
docker stats ai-dialogue-backend

# å®¹å™¨å†…è¿›ç¨‹
docker compose exec ai-dialogue-backend ps aux

# å®¹å™¨çŠ¶æ€
docker compose ps

# ç½‘ç»œè¿æ¥
sudo ss -tlnp | grep :8000
```

---

## å®‰å…¨æ³¨æ„äº‹é¡¹

### 1. APIå¯†é’¥ç®¡ç†
- ä¸è¦å°†APIå¯†é’¥æäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶
- ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–å¯†é’¥ç®¡ç†æœåŠ¡
- å®šæœŸè½®æ¢APIå¯†é’¥

### 2. ç½‘ç»œå®‰å…¨
- åœ¨ç”Ÿäº§ç¯å¢ƒä¸­é…ç½®é˜²ç«å¢™
- ä½¿ç”¨HTTPSå’ŒWSSåè®®
- é™åˆ¶è·¨åŸŸè®¿é—®

### 3. ç³»ç»Ÿå®‰å…¨
- å®šæœŸæ›´æ–°ç³»ç»Ÿå’Œä¾èµ–
- ä½¿ç”¨ä¸“ç”¨ç”¨æˆ·è¿è¡ŒæœåŠ¡
- é…ç½®é€‚å½“çš„æ–‡ä»¶æƒé™

### 4. æœåŠ¡å®‰å…¨
- å¯ç”¨SystemDå®‰å…¨ç‰¹æ€§
- é™åˆ¶èµ„æºä½¿ç”¨
- é…ç½®æ—¥å¿—è½®è½¬

---

## æ‰©å±•å’Œç»´æŠ¤

### å‡çº§éƒ¨ç½²
```bash
# å¼€å‘ç¯å¢ƒå‡çº§
git pull origin main
pip install -r requirements.txt --upgrade

# ç”Ÿäº§ç¯å¢ƒå‡çº§
cd /opt/ai-dialogue-backend
sudo -u backend git pull origin main
sudo -u backend ./venv/bin/pip install -r requirements.txt --upgrade
sudo systemctl restart ai-dialogue-backend
```

### å¤‡ä»½å’Œæ¢å¤
```bash
# å¤‡ä»½é…ç½®å’Œæ¨¡å‹
sudo tar -czf backup-$(date +%Y%m%d).tar.gz \
    /opt/ai-dialogue-backend/config/ \
    /opt/ai-dialogue-backend/model/ \
    /etc/systemd/system/ai-dialogue-backend.service

# æ¢å¤
sudo tar -xzf backup-20240101.tar.gz -C /
sudo systemctl daemon-reload
sudo systemctl restart ai-dialogue-backend
```

### ç›‘æ§å’Œå‘Šè­¦
- é…ç½®åº”ç”¨æ€§èƒ½ç›‘æ§ï¼ˆAPMï¼‰
- è®¾ç½®æ—¥å¿—å‘Šè­¦è§„åˆ™
- ç›‘æ§èµ„æºä½¿ç”¨æƒ…å†µ
- é…ç½®å¥åº·æ£€æŸ¥è„šæœ¬

---

## æŠ€æœ¯æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š
1. é¡¹ç›®æ–‡æ¡£ï¼š`docs/`
2. åº”ç”¨æ—¥å¿—ï¼š`/var/log/ai-dialogue-backend/` æˆ– `sudo journalctl -u ai-dialogue-backend`
3. å¥åº·æ£€æŸ¥ï¼š`http://localhost:8000/`

å¦‚éœ€è¿›ä¸€æ­¥ååŠ©ï¼Œè¯·æä¾›ï¼š
- é”™è¯¯æ—¥å¿—ä¿¡æ¯
- ç³»ç»Ÿç¯å¢ƒä¿¡æ¯
- é…ç½®æ–‡ä»¶å†…å®¹ï¼ˆéšè—æ•æ„Ÿä¿¡æ¯ï¼‰

**å¸¸ç”¨å‘½ä»¤æ€»ç»“ï¼š**

**å¼€å‘ç¯å¢ƒï¼š**
```bash
# å¯åŠ¨å¼€å‘æœåŠ¡
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

# å¥åº·æ£€æŸ¥
curl http://localhost:8000/
```

**Dockeréƒ¨ç½²ï¼š**
```bash
# ä¸€é”®éƒ¨ç½²
./deploy-docker.sh

# å®¹å™¨ç®¡ç†
docker compose {up -d|down|restart|ps}

# æ—¥å¿—æŸ¥çœ‹  
docker compose logs -f ai-dialogue-backend

# å¥åº·æ£€æŸ¥
curl http://localhost:8000/

# é‡æ–°æ„å»º
./deploy-docker.sh --build --no-cache

# åœæ­¢æœåŠ¡
./deploy-docker.sh --stop
```