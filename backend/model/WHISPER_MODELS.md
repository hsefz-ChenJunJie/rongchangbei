# Whisper æ¨¡å‹ç®¡ç†æŒ‡å—

æœ¬ç›®å½•ç”¨äºå­˜æ”¾ Whisper è¯­éŸ³è¯†åˆ«æ¨¡å‹ã€‚é¡¹ç›®æ”¯æŒä½¿ç”¨æœ¬åœ°é¢„è½¬æ¢çš„ CTranslate2 æ ¼å¼æ¨¡å‹ï¼Œä»¥è·å¾—æœ€ä½³æ€§èƒ½ã€‚

## ğŸ“ ç›®å½•ç»“æ„

```
model/
â”œâ”€â”€ whisper-models/           # Whisperæ¨¡å‹å­˜å‚¨ç›®å½•
â”‚   â”œâ”€â”€ base-ct2/            # baseæ¨¡å‹ï¼ˆæ¨èï¼‰
â”‚   â”œâ”€â”€ small-ct2/           # smallæ¨¡å‹
â”‚   â”œâ”€â”€ medium-ct2/          # mediumæ¨¡å‹
â”‚   â””â”€â”€ large-v3-ct2/        # large-v3æ¨¡å‹
â””â”€â”€ vosk-model/              # Voskæ¨¡å‹ç›®å½•ï¼ˆå¤‡ç”¨ï¼‰
```

## ğŸ¤– æ”¯æŒçš„æ¨¡å‹

| æ¨¡å‹åç§° | å¤§å° | å†…å­˜éœ€æ±‚ | å‡†ç¡®æ€§ | æ¨èç”¨é€” |
|----------|------|----------|--------|----------|
| tiny | ~39 MB | ~1GB | è¾ƒä½ | å¿«é€Ÿæµ‹è¯• |
| base | ~74 MB | ~1GB | è‰¯å¥½ | **é€šç”¨æ¨è** |
| small | ~244 MB | ~2GB | å¾ˆå¥½ | é«˜è´¨é‡éœ€æ±‚ |
| medium | ~769 MB | ~5GB | ä¼˜ç§€ | ä¸“ä¸šåº”ç”¨ |
| large-v2 | ~1550 MB | ~10GB | æä½³ | æœ€é«˜ç²¾åº¦ |
| large-v3 | ~1550 MB | ~10GB | æä½³ | æœ€æ–°æœ€ä½³ |
| distil-large-v3 | ~756 MB | ~6GB | æä½³ | é€Ÿåº¦ä¸ç²¾åº¦å¹³è¡¡ |

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. è‡ªåŠ¨ä¸‹è½½å’Œè½¬æ¢ï¼ˆæ¨èï¼‰

ä½¿ç”¨é¡¹ç›®æä¾›çš„è„šæœ¬è‡ªåŠ¨ä¸‹è½½å¹¶è½¬æ¢æ¨¡å‹ï¼š

```bash
# ä¸‹è½½æ¨èçš„baseæ¨¡å‹
python scripts/download_whisper_models.py --model base --verify

# ä¸‹è½½æ‰€æœ‰æ¨èæ¨¡å‹ï¼ˆbase, small, mediumï¼‰
python scripts/download_whisper_models.py --all --verify

# ä¸‹è½½ç‰¹å®šæ¨¡å‹
python scripts/download_whisper_models.py --model large-v3 --quantization int8
```

### 2. æ‰‹åŠ¨ä¸‹è½½å’Œè½¬æ¢

å¦‚æœéœ€è¦æ‰‹åŠ¨æ“ä½œï¼š

```bash
# å®‰è£…è½¬æ¢å·¥å…·
pip install ctranslate2 transformers[torch]

# è½¬æ¢æ¨¡å‹
ct2-transformers-converter \
    --model openai/whisper-base \
    --output_dir model/whisper-models/base-ct2 \
    --copy_files tokenizer.json preprocessor_config.json \
    --quantization int8
```

### 3. é…ç½®åº”ç”¨ä½¿ç”¨Whisper

åœ¨ `.env` æ–‡ä»¶ä¸­é…ç½®ï¼š

```env
# å¯ç”¨Whisper STTæœåŠ¡
STT_ENGINE=whisper
USE_WHISPER=true

# æ¨¡å‹é…ç½®
WHISPER_MODEL_NAME=base
WHISPER_MODEL_PATH=model/whisper-models
WHISPER_DEVICE=auto
WHISPER_COMPUTE_TYPE=int8
```

## âš™ï¸ é…ç½®é€‰é¡¹è¯¦è§£

### è®¾å¤‡é€‰æ‹©
- `WHISPER_DEVICE=auto` - è‡ªåŠ¨æ£€æµ‹ï¼ˆæ¨èï¼‰
- `WHISPER_DEVICE=cpu` - ä½¿ç”¨CPU
- `WHISPER_DEVICE=cuda` - ä½¿ç”¨GPUï¼ˆéœ€è¦CUDAæ”¯æŒï¼‰

### è®¡ç®—ç±»å‹
- `WHISPER_COMPUTE_TYPE=int8` - CPUæ¨èï¼ŒèŠ‚çœå†…å­˜
- `WHISPER_COMPUTE_TYPE=float32` - CPUé«˜ç²¾åº¦
- `WHISPER_COMPUTE_TYPE=float16` - GPUæ¨è
- `WHISPER_COMPUTE_TYPE=int8_float16` - GPUèŠ‚çœæ˜¾å­˜

### è¯­è¨€è®¾ç½®
- `WHISPER_LANGUAGE=null` - è‡ªåŠ¨æ£€æµ‹è¯­è¨€ï¼ˆæ¨èï¼‰
- `WHISPER_LANGUAGE=zh` - å¼ºåˆ¶ä¸­æ–‡
- `WHISPER_LANGUAGE=en` - å¼ºåˆ¶è‹±æ–‡

## ğŸ”§ æ€§èƒ½ä¼˜åŒ–

### å†…å­˜ä¼˜åŒ–
1. ä½¿ç”¨int8é‡åŒ–ï¼š`WHISPER_COMPUTE_TYPE=int8`
2. é€‰æ‹©åˆé€‚çš„æ¨¡å‹å¤§å°
3. å¯ç”¨VADè¿‡æ»¤ï¼š`WHISPER_VAD_FILTER=true`

### é€Ÿåº¦ä¼˜åŒ–
1. ä½¿ç”¨GPUæ¨ç†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
2. é€‰æ‹©distilæ¨¡å‹ï¼ˆå¦‚distil-large-v3ï¼‰
3. é€‚å½“è°ƒæ•´beam_sizeï¼š`WHISPER_BEAM_SIZE=5`

### å‡†ç¡®æ€§ä¼˜åŒ–
1. ä½¿ç”¨largeræ¨¡å‹
2. æŒ‡å®šç›®æ ‡è¯­è¨€
3. å¯ç”¨è¯çº§æ—¶é—´æˆ³ï¼š`WHISPER_WORD_TIMESTAMPS=true`

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

**Q: æ¨¡å‹åŠ è½½å¤±è´¥**
```
A: æ£€æŸ¥æ¨¡å‹è·¯å¾„å’Œæ–‡ä»¶å®Œæ•´æ€§
   ls -la model/whisper-models/base-ct2/
   åº”è¯¥åŒ…å«ï¼šconfig.json, model.bin ç­‰æ–‡ä»¶
```

**Q: å†…å­˜ä¸è¶³**
```
A: åˆ‡æ¢åˆ°æ›´å°çš„æ¨¡å‹æˆ–ä½¿ç”¨é‡åŒ–
   WHISPER_MODEL_NAME=base  # è€Œä¸æ˜¯large
   WHISPER_COMPUTE_TYPE=int8
```

**Q: GPUä¸è¢«è¯†åˆ«**
```
A: æ£€æŸ¥CUDAç¯å¢ƒ
   python -c "import torch; print(torch.cuda.is_available())"
```

**Q: è½¬å½•è´¨é‡ä½**
```
A: å°è¯•ä»¥ä¸‹ä¼˜åŒ–ï¼š
   1. ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹
   2. æŒ‡å®šè¯­è¨€ï¼šWHISPER_LANGUAGE=zh
   3. æ£€æŸ¥éŸ³é¢‘è´¨é‡ï¼ˆé‡‡æ ·ç‡16kHzï¼‰
```

### æ¨¡å‹éªŒè¯

éªŒè¯æ¨¡å‹æ˜¯å¦æ­£ç¡®å®‰è£…ï¼š

```bash
python -c "
from faster_whisper import WhisperModel
model = WhisperModel('model/whisper-models/base-ct2', device='cpu')
print('æ¨¡å‹åŠ è½½æˆåŠŸ!')
"
```

## ğŸ“Š æ€§èƒ½åŸºå‡†

åœ¨ Intel i7-10700K CPUä¸Šçš„æµ‹è¯•ç»“æœï¼š

| æ¨¡å‹ | å®æ—¶å€æ•° | å†…å­˜ä½¿ç”¨ | WER (ä¸­æ–‡) |
|------|----------|----------|------------|
| base | 2.1x | 1.2GB | 8.5% |
| small | 1.8x | 2.1GB | 7.2% |
| medium | 1.3x | 4.8GB | 6.1% |

*å®æ—¶å€æ•°ï¼šå¤„ç†1åˆ†é’ŸéŸ³é¢‘éœ€è¦çš„æ—¶é—´å€æ•°ï¼Œè¶Šå°è¶Šå¥½*

## ğŸ”„ æ¨¡å‹æ›´æ–°

å®šæœŸæ£€æŸ¥æ˜¯å¦æœ‰æ–°ç‰ˆæœ¬çš„æ¨¡å‹ï¼š

1. å…³æ³¨ [Hugging Face Whisper Models](https://huggingface.co/models?search=whisper)
2. ä¸‹è½½æ–°æ¨¡å‹åˆ°ä¸´æ—¶ç›®å½•æµ‹è¯•
3. éªŒè¯æ€§èƒ½åæ›¿æ¢ç°æœ‰æ¨¡å‹
4. æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹åç§°

## ğŸ“š æ›´å¤šèµ„æº

- [OpenAI Whisper å®˜æ–¹ä»“åº“](https://github.com/openai/whisper)
- [faster-whisper é¡¹ç›®](https://github.com/systran/faster-whisper)
- [CTranslate2 æ–‡æ¡£](https://opennmt.net/CTranslate2/)
- [æ¨¡å‹è½¬æ¢æŒ‡å—](https://github.com/systran/faster-whisper#model-conversion)