version: '3.8'

services:
  ai-backend:
    build: 
      context: .
      dockerfile: Dockerfile
    container_name: ai-dialogue-backend
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      # 基础配置
      - HOST=0.0.0.0
      - PORT=8000
      - DEBUG=false
      - LOG_LEVEL=INFO
      
      # LLM服务配置（请设置您的API密钥）
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY:-}
      - OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
      
      # STT服务配置
      - USE_REAL_VOSK=false
      - VOSK_MODEL_PATH=/app/model/vosk-model
      - VOSK_SAMPLE_RATE=16000
      
      # 安全配置
      - ALLOWED_ORIGINS=["*"]
    volumes:
      # 持久化模型数据
      - ai-backend-models:/app/model
      # 持久化日志
      - ai-backend-logs:/app/logs
      # 可选：挂载本地模型目录（如果有预下载的模型）
      # - ./model:/app/model:ro
    networks:
      - ai-network
    deploy:
      resources:
        limits:
          # 限制CPU和内存使用
          cpus: '2.0'
          memory: 4G
        reservations:
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # 可选：Nginx反向代理服务
  nginx:
    image: nginx:alpine
    container_name: ai-dialogue-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      # 可选：SSL证书
      # - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - ai-backend
    networks:
      - ai-network
    # 如果不需要Nginx，可以注释掉这个服务

networks:
  ai-network:
    driver: bridge

volumes:
  ai-backend-models:
    driver: local
  ai-backend-logs:
    driver: local