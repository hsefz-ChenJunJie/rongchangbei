version: '3.8'

services:
  ai-backend:
    build: 
      context: .
      dockerfile: Dockerfile
    container_name: ai-dialogue-backend
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      # 基础配置
      - HOST=0.0.0.0
      - PORT=8000
      - DEBUG=false
      - LOG_LEVEL=INFO
      
      # LLM服务配置（请设置您的API密钥）
      - OPENROUTER_API_KEY=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
      - OPENROUTER_MODEL=qwen/qwen3-235b-a22b:free
      - OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
      
      # STT服务配置
      - USE_REAL_VOSK=true
      - VOSK_MODEL_PATH=/app/model/vosk-model
      - VOSK_SAMPLE_RATE=16000
      
      # 安全配置
      - ALLOWED_ORIGINS=["*"]
    volumes:
      # 挂载本地模型目录（包含vosk-model）
      - ./model:/app/model:ro
      # 持久化日志
      - ai-backend-logs:/app/logs
    networks:
      - ai-network
    # deploy:
    #   resources:
    #     limits:
    #       # 限制CPU和内存使用
    #       cpus: '2.0'
    #       memory: 4G
    #     reservations:
    #       memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # 可选：Nginx反向代理服务
  # nginx:
  #   image: nginx:alpine
  #   container_name: ai-dialogue-nginx
  #   restart: unless-stopped
  #   ports:
  #     - "80:80"
  #     - "443:443"
  #   volumes:
  #     - ./nginx.conf:/etc/nginx/nginx.conf:ro
  #     # 可选：SSL证书
  #     # - ./ssl:/etc/nginx/ssl:ro
  #   depends_on:
  #     - ai-backend
  #   networks:
  #     - ai-network
  #   # 如果不需要Nginx，可以注释掉这个服务

networks:
  ai-network:
    driver: bridge

volumes:
  ai-backend-logs:
    driver: local